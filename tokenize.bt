// Copyright (c) 2023-present Lukas Neubert.
// This Source Code is subject to the terms of the Mozilla Public License 2.0.
package main

enum TokKind {
	unknown
	name
	string
	number
	dot
	colon
	comma
	lpar
	rpar
	lcur
	rcur
	lbr
	rbr
	assign
	arrow
	lt
	gt
	pipe
	amp
	question
	key_class
	key_const
	key_declare
	key_export
	key_interface
	key_module
	key_readonly
}

fun (k TokKind) str()string{
	match k {
		.unknown { return 'unknown' }
		.name { return 'name' }
		.string { return 'string' }
		.number { return 'number' }
		.dot { return '.' }
		.colon { return ':' }
		.comma { return ',' }
		.lpar { return '(' }
		.rpar { return ')' }
		.lcur { return '{' }
		.rcur { return '}' }
		.lbr { return '[' }
		.rbr { return ']' }
		.assign { return '=' }
		.arrow { return '=>' }
		.lt { return '<' }
		.gt { return '>' }
		.pipe { return '|' }
		.amp { return '&' }
		.question { return '?' }
		.key_class { return 'class' }
		.key_const { return 'const' }
		.key_declare { return 'declare' }
		.key_export { return 'export' }
		.key_interface { return 'interface' }
		.key_module { return 'module' }
		.key_readonly { return 'readonly' }
	}
}

fun keyword_to_kind(name string) TokKind {
	match name {
		'class' { return .key_class }
		'const' { return .key_const }
		'declare' { return .key_declare }
		'export' { return .key_export }
		'interface' { return .key_interface }
		'module' { return .key_module }
		'readonly' { return .key_readonly }
		else { return .name }
	}
}

struct Token {
	kind TokKind
	val string
	line i32
}

struct Tokenizer {
	text string
mut:
	pos i32
	line i32 := 1
	should_abort bool
}

fun (t Tokenizer) new_token(kind TokKind, val string) Token {
	return Token{
		kind = kind
		val = val
		line = t.line
	}
}

fun tokenize(text string) []Token {
	mut t := Tokenizer{
		text = text
	}

	mut tokens := []Token
	for t.pos < t.text.length {
		tokens.push(t.next_token())
	}
	return tokens
}

fun (mut t Tokenizer) next_token() Token {
	for t.pos < t.text.length {
		c := t.text[t.pos]
		t.pos += 1

		if is_name_char(c) {
			start := t.pos - 1
			for t.pos < t.text.length and is_name_char(t.text[t.pos]) {
				t.pos += 1
			}

			val := t.text.substr(start, t.pos)
			kind := keyword_to_kind(val)

			return t.new_token(kind, val)
		}

		if is_digit(c) or c == `-` {
			start := t.pos
			for t.pos < t.text.length and is_digit(t.text[t.pos]) {
				t.pos += 1
			}
			return t.new_token(.number, t.text.substr(start, t.pos))
		}

		match c {
			// String
			`'` {
				start := t.pos
				for t.pos < t.text.length and t.text[t.pos] != `'` {
					t.pos += 1
				}
				t.pos += 1
				return t.new_token(.string, t.text.substr(start, t.pos - 1))
			}
			`.` {
				return t.new_token(.dot, '')
			}
			`:` {
				return t.new_token(.colon, '')
			}
			`,` {
				return t.new_token(.comma, '')
			}
			`(` {
				return t.new_token(.lpar, '')
			}
			`)` {
				return t.new_token(.rpar, '')
			}
			`{` {
				return t.new_token(.lcur, '')
			}
			`}` {
				return t.new_token(.rcur, '')
			}
			`[` {
				return t.new_token(.lbr, '')
			}
			`]` {
				return t.new_token(.rbr, '')
			}
			`=` {
				if t.text[t.pos + 1] == `>` {
					t.pos += 1
					return t.new_token(.arrow, '')
				}
				return t.new_token(.assign, '')
			}
			`<` {
				return t.new_token(.lt, '')
			}
			`>` {
				return t.new_token(.gt, '')
			}
			`|` {
				return t.new_token(.pipe, '')
			}
			`&` {
				return t.new_token(.amp, '')
			}
			`?` {
				return t.new_token(.question, '')
			}
			// Skip whitespace and semicolon
			`;`, ` `, `\t` {}
			`\n` {
				t.line += 1
			}
			// Skip comments
			`/`, `*` {
				t.skip_line()
			}
			else {
				eprintln('unexpected char `${c.ascii()}` in line ${t.line}')
				exit(1)
			}
		}
	}
}

fun (mut t Tokenizer) skip_line() {
	for t.pos < t.text.length and t.text[t.pos] != `\n` {
		t.pos += 1
	}
	t.pos += 1
	t.line += 1
}

fun is_name_char(c u8) bool {
	return c >= `a` and c <= `z` or c >= `A` and c <= `Z` or c == `_`
}

fun is_digit(c u8) bool {
	return c >= `0` and c <= `9`
}
